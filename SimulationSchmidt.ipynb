{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation of lifetimes for Schmidt distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, sys, yaml, re\n",
    "from IPython.display import display, Markdown, Latex #Can write latex too!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecayChain(yaml.YAMLObject):\n",
    "    \n",
    "    yaml_tag = u'!DecayChain'\n",
    "    \n",
    "    def __init__(self, idd=\"\", be=\"\", pi=\"\", ie=\"\", it=\"\", ea=[], eas=[], ta=[]):\n",
    "        self.ID = idd\n",
    "        self.BeamEnergy = be\n",
    "        self.Pixel = pi\n",
    "        self.ImplantEnergy = ie\n",
    "        self.ImplantTime = it\n",
    "        self.EAlpha, self.EAlphaSigma, self.TAlpha = ea, eas, ta\n",
    "\n",
    "class SetDecayChains:\n",
    "    \n",
    "    def __init__(self, path='', ids=[]):\n",
    "        s_files = \" \".join(os.listdir(path))\n",
    "        files = []\n",
    "        for s in ids:\n",
    "            files += (sorted(re.findall(string=s_files, pattern=\"Chain\"+s+\"\\d+.yml\")))\n",
    "        print(\"Reading the following files:\", files)\n",
    "        self.Chains = []\n",
    "        for f in files:\n",
    "            f_in = open(path+f, 'r')\n",
    "            self.Chains.append(yaml.load(f_in))\n",
    "            f_in.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the following files: ['Chain1401.yml', 'Chain1402.yml', 'Chain1403.yml', 'Chain1404.yml', 'Chain1405.yml', 'Chain1406.yml', 'Chain1407.yml', 'Chain1101.yml', 'Chain1102.yml', 'Chain1103.yml', 'Chain1104.yml', 'Chain1701.yml', 'Chain1702.yml', 'Chain1703.yml']\n",
      "Max steps= 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  2.27000000e-01,   3.78000000e-01,              nan],\n",
       "       [  6.45000000e-02,   3.66000000e-01,              nan],\n",
       "       [  2.61000000e-01,   1.15000000e+00,   3.43000000e-01],\n",
       "       [  1.46000000e+00,   2.62000000e-02,   4.32000000e-01],\n",
       "       [  3.45000000e-01,   3.69000000e-01,   1.44000000e+01],\n",
       "       [  2.10000000e-01,   1.05000000e+00,   8.27000000e+00],\n",
       "       [  8.15000000e-01,   2.33000000e+00,   2.89000000e+00],\n",
       "       [  2.56200000e-01,   1.40270000e+00,   1.97750000e+00],\n",
       "       [  6.61000000e-02,   1.55000000e+00,   2.36380000e+00],\n",
       "       [  2.35070000e+00,   2.25822000e+01,   6.01855000e+01],\n",
       "       [  5.36000000e-02,   4.67100000e-01,   9.08000000e-02],\n",
       "       [  2.14000000e-01,   1.54000000e+00,   7.57000000e+00],\n",
       "       [  5.91000000e-02,   8.24000000e-01,              nan],\n",
       "       [  4.55000000e-02,   1.42000000e-02,              nan]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_path = \"data/\"\n",
    "s_id = [\"14\", \"11\", \"17\"]\n",
    "\n",
    "setDC = SetDecayChains(s_path, s_id)\n",
    "max_steps = 0\n",
    "for chain in setDC.Chains:\n",
    "    if len(chain.TAlpha) > max_steps:\n",
    "        max_steps = len(chain.TAlpha)\n",
    "print(\"Max steps=\", max_steps)\n",
    "times = np.zeros((len(setDC.Chains), max_steps))\n",
    "for row, chain in enumerate(setDC.Chains):\n",
    "    steps = len(chain.TAlpha)\n",
    "    for i in range(max_steps):\n",
    "        if i < steps:\n",
    "            times[row][i] = chain.TAlpha[i]\n",
    "        else:\n",
    "            times[row][i] = np.nan       \n",
    "times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting out chains of different lengths into arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to simulate lifetime values for the number of chains we have in the set for enough number of times. To simplify, maybe it would be nice to reshuffle the set into two subsets depending on the length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_j = np.count_nonzero(~np.isnan(times), axis=1)\n",
    "N_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind1 = np.argwhere(N_j == max_steps)[:,0]\n",
    "ind1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1, 12, 13])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind2 = np.argwhere(N_j == max_steps-1)[:,0]\n",
    "ind2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.61000000e-01,   1.15000000e+00,   3.43000000e-01],\n",
       "       [  1.46000000e+00,   2.62000000e-02,   4.32000000e-01],\n",
       "       [  3.45000000e-01,   3.69000000e-01,   1.44000000e+01],\n",
       "       [  2.10000000e-01,   1.05000000e+00,   8.27000000e+00],\n",
       "       [  8.15000000e-01,   2.33000000e+00,   2.89000000e+00],\n",
       "       [  2.56200000e-01,   1.40270000e+00,   1.97750000e+00],\n",
       "       [  6.61000000e-02,   1.55000000e+00,   2.36380000e+00],\n",
       "       [  2.35070000e+00,   2.25822000e+01,   6.01855000e+01],\n",
       "       [  5.36000000e-02,   4.67100000e-01,   9.08000000e-02],\n",
       "       [  2.14000000e-01,   1.54000000e+00,   7.57000000e+00]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times1 = times[ind1]\n",
    "times1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.227 ,  0.378 ],\n",
       "       [ 0.0645,  0.366 ],\n",
       "       [ 0.0591,  0.824 ],\n",
       "       [ 0.0455,  0.0142]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times2 = times[ind2][:, :-1]\n",
    "times2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, these additional steps may only confuse the reader!!! For the geometrical mean with nans I can implement something in cython. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample from exponential distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 14, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbr_sets = 10\n",
    "shape = (nbr_sets, *np.shape(times))\n",
    "sim = np.random.exponential(scale=1, size=shape)\n",
    "np.shape(sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masking to insert the nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "masked_array(data =\n",
       " [[False False  True]\n",
       " [False False  True]\n",
       " [False False False]\n",
       " [False False False]\n",
       " [False False False]\n",
       " [False False False]\n",
       " [False False False]\n",
       " [False False False]\n",
       " [False False False]\n",
       " [False False False]\n",
       " [False False False]\n",
       " [False False False]\n",
       " [False False  True]\n",
       " [False False  True]],\n",
       "             mask =\n",
       " False,\n",
       "       fill_value = True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2d = np.ma.masked_array(np.isnan(times))\n",
    "m2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 3, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask3d = np.ma.dstack([m2d]*nbr_sets)\n",
    "np.shape(mask3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sooooo much easier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Short chains data set duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_nan_mean(data):\n",
    "    ret = np.empty(np.shape(data)[0])\n",
    "    for i in range(np.shape(data)[0]):\n",
    "        temp = 1\n",
    "        steps = 0\n",
    "        for j in range(np.shape(data)[1]):\n",
    "            if ~np.isnan(data[i,j]):\n",
    "                temp *= data[i,j]\n",
    "            else:\n",
    "                break\n",
    "            steps += 1\n",
    "        ret[i] = temp**(1./steps)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.227 ,  0.0645,  0.261 ,  1.46  ,  0.345 ,  0.21  ,  0.815 ,\n",
       "         0.2562,  0.0661,  2.3507,  0.0536,  0.214 ,  0.0591,  0.0455]),\n",
       " array([[[  2.27000000e-01,   3.78000000e-01,              nan],\n",
       "         [  6.45000000e-02,   3.66000000e-01,              nan],\n",
       "         [  2.61000000e-01,   1.15000000e+00,   3.43000000e-01],\n",
       "         [  1.46000000e+00,   2.62000000e-02,   4.32000000e-01],\n",
       "         [  3.45000000e-01,   3.69000000e-01,   1.44000000e+01],\n",
       "         [  2.10000000e-01,   1.05000000e+00,   8.27000000e+00],\n",
       "         [  8.15000000e-01,   2.33000000e+00,   2.89000000e+00],\n",
       "         [  2.56200000e-01,   1.40270000e+00,   1.97750000e+00],\n",
       "         [  6.61000000e-02,   1.55000000e+00,   2.36380000e+00],\n",
       "         [  2.35070000e+00,   2.25822000e+01,   6.01855000e+01],\n",
       "         [  5.36000000e-02,   4.67100000e-01,   9.08000000e-02],\n",
       "         [  2.14000000e-01,   1.54000000e+00,   7.57000000e+00],\n",
       "         [  5.91000000e-02,   8.24000000e-01,              nan],\n",
       "         [  4.55000000e-02,   1.42000000e-02,              nan]],\n",
       " \n",
       "        [[  2.27000000e-01,   3.78000000e-01,              nan],\n",
       "         [  6.45000000e-02,   3.66000000e-01,              nan],\n",
       "         [  2.61000000e-01,   1.15000000e+00,   3.43000000e-01],\n",
       "         [  1.46000000e+00,   2.62000000e-02,   4.32000000e-01],\n",
       "         [  3.45000000e-01,   3.69000000e-01,   1.44000000e+01],\n",
       "         [  2.10000000e-01,   1.05000000e+00,   8.27000000e+00],\n",
       "         [  8.15000000e-01,   2.33000000e+00,   2.89000000e+00],\n",
       "         [  2.56200000e-01,   1.40270000e+00,   1.97750000e+00],\n",
       "         [  6.61000000e-02,   1.55000000e+00,   2.36380000e+00],\n",
       "         [  2.35070000e+00,   2.25822000e+01,   6.01855000e+01],\n",
       "         [  5.36000000e-02,   4.67100000e-01,   9.08000000e-02],\n",
       "         [  2.14000000e-01,   1.54000000e+00,   7.57000000e+00],\n",
       "         [  5.91000000e-02,   8.24000000e-01,              nan],\n",
       "         [  4.55000000e-02,   1.42000000e-02,              nan]]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbr_sets = 2\n",
    "shape = (nbr_sets, *np.shape(times))\n",
    "sim = np.empty(shape)\n",
    "for i in range(nbr_sets):\n",
    "    sim[i] = times\n",
    "sim[0, :, 0], sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulated chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.47295106,  0.13826594,         nan],\n",
       "        [ 0.38282398,  1.06258346,         nan],\n",
       "        [ 2.53596589,  1.740428  ,  1.91222996],\n",
       "        ..., \n",
       "        [ 1.35843455,  1.1423758 ,  0.27904258],\n",
       "        [ 0.7360603 ,  0.10834985,         nan],\n",
       "        [ 0.8911183 ,  0.47844164,         nan]],\n",
       "\n",
       "       [[ 0.02481661,  0.7246067 ,         nan],\n",
       "        [ 1.06547893,  1.23697359,         nan],\n",
       "        [ 0.34521624,  2.33060285,  0.47324651],\n",
       "        ..., \n",
       "        [ 0.13274914,  0.20452968,  0.17858752],\n",
       "        [ 4.33654876,  1.05441854,         nan],\n",
       "        [ 0.92337613,  4.15171197,         nan]],\n",
       "\n",
       "       [[ 0.60823939,  1.10775691,         nan],\n",
       "        [ 0.63352722,  0.04008763,         nan],\n",
       "        [ 0.82440384,  0.02573784,  0.89047258],\n",
       "        ..., \n",
       "        [ 1.32088057,  0.24126684,  1.13691169],\n",
       "        [ 0.39146004,  0.05700766,         nan],\n",
       "        [ 0.01565506,  0.85139508,         nan]],\n",
       "\n",
       "       ..., \n",
       "       [[ 0.01353299,  0.58340357,         nan],\n",
       "        [ 2.14041221,  1.41464392,         nan],\n",
       "        [ 1.62314572,  0.27091842,  1.1352804 ],\n",
       "        ..., \n",
       "        [ 0.17822165,  0.87390516,  0.01168375],\n",
       "        [ 0.80096502,  0.30704605,         nan],\n",
       "        [ 2.02554414,  1.10918679,         nan]],\n",
       "\n",
       "       [[ 1.7768199 ,  1.32712257,         nan],\n",
       "        [ 0.774862  ,  1.20904098,         nan],\n",
       "        [ 0.75567543,  0.2213127 ,  1.79059328],\n",
       "        ..., \n",
       "        [ 0.81502309,  0.35439556,  0.48167395],\n",
       "        [ 0.1179053 ,  2.37497027,         nan],\n",
       "        [ 0.72348194,  0.01560939,         nan]],\n",
       "\n",
       "       [[ 0.17877845,  2.03763354,         nan],\n",
       "        [ 0.7160464 ,  0.19361955,         nan],\n",
       "        [ 0.34052768,  0.84831038,  0.40850463],\n",
       "        ..., \n",
       "        [ 0.8215564 ,  0.0808171 ,  0.82749012],\n",
       "        [ 2.36172347,  0.71580558,         nan],\n",
       "        [ 0.3671653 ,  2.47849361,         nan]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbr_sets = 30000\n",
    "shape = (nbr_sets, *np.shape(times))\n",
    "sim = np.random.exponential(scale=1, size=shape)\n",
    "for i in range(nbr_sets):\n",
    "    sim[i][np.isnan(times)] = np.nan\n",
    "sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3.93036514e-01   7.33020671e-01   9.76850955e-01   1.52887052e-01\n",
      "   6.70331168e-03   6.74732804e-01   8.78257340e+00   3.41375667e-01\n",
      "   4.79490058e-01   2.56202980e-01   1.35685774e+00   2.87815784e-01\n",
      "   6.37565314e-01   2.16967121e-02]\n",
      "[ 1.03857075  0.72533713  0.9966775  ...,  0.8016078   0.89532149\n",
      "  0.74665797]\n"
     ]
    }
   ],
   "source": [
    "theta = np.log(sim)\n",
    "theta_var = np.zeros(np.shape(theta))\n",
    "gen_Schmidt = np.zeros(np.shape(theta)[:-1])\n",
    "for i in range(nbr_sets):\n",
    "    theta_var[i] = np.square(theta[i] - np.nanmean(theta[i], axis=0))\n",
    "    gen_Schmidt[i] = g_nan_mean(theta_var[i])\n",
    "\n",
    "print(gen_Schmidt[0])\n",
    "#theta_var\n",
    "gen_Schmidt = np.sqrt(np.mean(gen_Schmidt, axis=1))\n",
    "print(gen_Schmidt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected generalised Schmidt value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86179162222916006"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E_Schmidt = np.mean(gen_Schmidt)\n",
    "E_Schmidt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6265521560630567, 1.1331438681832808)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(gen_Schmidt, q=5), np.percentile(gen_Schmidt, q=95)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

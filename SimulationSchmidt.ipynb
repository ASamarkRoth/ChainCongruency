{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation of lifetimes for Schmidt distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, sys, yaml, re\n",
    "from IPython.display import display, Markdown, Latex #Can write latex too!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecayChain(yaml.YAMLObject):\n",
    "    \n",
    "    yaml_tag = u'!DecayChain'\n",
    "    \n",
    "    def __init__(self, idd=\"\", be=\"\", pi=\"\", ie=\"\", it=\"\", ea=[], eas=[], ta=[]):\n",
    "        self.ID = idd\n",
    "        self.BeamEnergy = be\n",
    "        self.Pixel = pi\n",
    "        self.ImplantEnergy = ie\n",
    "        self.ImplantTime = it\n",
    "        self.EAlpha, self.EAlphaSigma, self.TAlpha = ea, eas, ta\n",
    "\n",
    "class SetDecayChains:\n",
    "    \n",
    "    def __init__(self, path='', ids=[]):\n",
    "        s_files = \" \".join(os.listdir(path))\n",
    "        files = []\n",
    "        for s in ids:\n",
    "            files += (sorted(re.findall(string=s_files, pattern=\"Chain\"+s+\"\\d+.yml\")))\n",
    "        print(\"Reading the following files:\", files)\n",
    "        self.Chains = []\n",
    "        for f in files:\n",
    "            f_in = open(path+f, 'r')\n",
    "            self.Chains.append(yaml.load(f_in))\n",
    "            f_in.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the following files: ['Chain1401.yml', 'Chain1402.yml', 'Chain1403.yml', 'Chain1404.yml', 'Chain1405.yml', 'Chain1406.yml', 'Chain1407.yml', 'Chain1101.yml', 'Chain1102.yml', 'Chain1103.yml', 'Chain1104.yml', 'Chain1701.yml', 'Chain1702.yml', 'Chain1703.yml']\n",
      "Max steps= 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  2.27000000e-01,   3.78000000e-01,              nan],\n",
       "       [  6.45000000e-02,   3.66000000e-01,              nan],\n",
       "       [  2.61000000e-01,   1.15000000e+00,   3.43000000e-01],\n",
       "       [  1.46000000e+00,   2.62000000e-02,   4.32000000e-01],\n",
       "       [  3.45000000e-01,   3.69000000e-01,   1.44000000e+01],\n",
       "       [  2.10000000e-01,   1.05000000e+00,   8.27000000e+00],\n",
       "       [  8.15000000e-01,   2.33000000e+00,   2.89000000e+00],\n",
       "       [  2.56200000e-01,   1.40270000e+00,   1.97750000e+00],\n",
       "       [  6.61000000e-02,   1.55000000e+00,   2.36380000e+00],\n",
       "       [  2.35070000e+00,   2.25822000e+01,   6.01855000e+01],\n",
       "       [  5.36000000e-02,   4.67100000e-01,   9.08000000e-02],\n",
       "       [  2.14000000e-01,   1.54000000e+00,   7.57000000e+00],\n",
       "       [  5.91000000e-02,   8.24000000e-01,              nan],\n",
       "       [  4.55000000e-02,   1.42000000e-02,              nan]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_path = \"E115_Chains/\"\n",
    "s_id = [\"14\", \"11\", \"17\"]\n",
    "\n",
    "setDC = SetDecayChains(s_path, s_id)\n",
    "max_steps = 0\n",
    "for chain in setDC.Chains:\n",
    "    if len(chain.TAlpha) > max_steps:\n",
    "        max_steps = len(chain.TAlpha)\n",
    "print(\"Max steps=\", max_steps)\n",
    "times = np.zeros((len(setDC.Chains), max_steps))\n",
    "for row, chain in enumerate(setDC.Chains):\n",
    "    steps = len(chain.TAlpha)\n",
    "    for i in range(max_steps):\n",
    "        if i < steps:\n",
    "            times[row][i] = chain.TAlpha[i]\n",
    "        else:\n",
    "            times[row][i] = np.nan       \n",
    "times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting out chains of different lengths into arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to simulate lifetime values for the number of chains we have in the set for enough number of times. To simplify, maybe it would be nice to reshuffle the set into two subsets depending on the length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_j = np.count_nonzero(~np.isnan(times), axis=1)\n",
    "N_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind1 = np.argwhere(N_j == max_steps)[:,0]\n",
    "ind1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1, 12, 13])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind2 = np.argwhere(N_j == max_steps-1)[:,0]\n",
    "ind2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.61000000e-01,   1.15000000e+00,   3.43000000e-01],\n",
       "       [  1.46000000e+00,   2.62000000e-02,   4.32000000e-01],\n",
       "       [  3.45000000e-01,   3.69000000e-01,   1.44000000e+01],\n",
       "       [  2.10000000e-01,   1.05000000e+00,   8.27000000e+00],\n",
       "       [  8.15000000e-01,   2.33000000e+00,   2.89000000e+00],\n",
       "       [  2.56200000e-01,   1.40270000e+00,   1.97750000e+00],\n",
       "       [  6.61000000e-02,   1.55000000e+00,   2.36380000e+00],\n",
       "       [  2.35070000e+00,   2.25822000e+01,   6.01855000e+01],\n",
       "       [  5.36000000e-02,   4.67100000e-01,   9.08000000e-02],\n",
       "       [  2.14000000e-01,   1.54000000e+00,   7.57000000e+00]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times1 = times[ind1]\n",
    "times1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.227 ,  0.378 ],\n",
       "       [ 0.0645,  0.366 ],\n",
       "       [ 0.0591,  0.824 ],\n",
       "       [ 0.0455,  0.0142]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times2 = times[ind2][:, :-1]\n",
    "times2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, these additional steps may only confuse the reader!!! For the geometrical mean with nans I can implement something in cython. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample from exponential distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 14, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbr_sets = 10\n",
    "shape = (nbr_sets, *np.shape(times))\n",
    "sim = np.random.exponential(scale=1, size=shape)\n",
    "np.shape(sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masking to insert the nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "masked_array(data =\n",
       " [[False False  True]\n",
       " [False False  True]\n",
       " [False False False]\n",
       " [False False False]\n",
       " [False False False]\n",
       " [False False False]\n",
       " [False False False]\n",
       " [False False False]\n",
       " [False False False]\n",
       " [False False False]\n",
       " [False False False]\n",
       " [False False False]\n",
       " [False False  True]\n",
       " [False False  True]],\n",
       "             mask =\n",
       " False,\n",
       "       fill_value = True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2d = np.ma.masked_array(np.isnan(times))\n",
    "m2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 3, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask3d = np.ma.dstack([m2d]*nbr_sets)\n",
    "np.shape(mask3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (10,14,3) (14,3,10) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-7dc767031059>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask3d\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (10,14,3) (14,3,10) "
     ]
    }
   ],
   "source": [
    "sim[mask3d]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sooooo much easier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Short chains data set duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_nan_mean(data):\n",
    "    ret = np.empty(np.shape(data)[0])\n",
    "    for i in range(np.shape(data)[0]):\n",
    "        temp = 1\n",
    "        steps = 0\n",
    "        for j in range(np.shape(data)[1]):\n",
    "            if ~np.isnan(data[i,j]):\n",
    "                temp *= data[i,j]\n",
    "            else:\n",
    "                break\n",
    "            steps += 1\n",
    "        ret[i] = temp**(1./steps)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.227 ,  0.0645,  0.261 ,  1.46  ,  0.345 ,  0.21  ,  0.815 ,\n",
       "         0.2562,  0.0661,  2.3507,  0.0536,  0.214 ,  0.0591,  0.0455]),\n",
       " array([[[  2.27000000e-01,   3.78000000e-01,              nan],\n",
       "         [  6.45000000e-02,   3.66000000e-01,              nan],\n",
       "         [  2.61000000e-01,   1.15000000e+00,   3.43000000e-01],\n",
       "         [  1.46000000e+00,   2.62000000e-02,   4.32000000e-01],\n",
       "         [  3.45000000e-01,   3.69000000e-01,   1.44000000e+01],\n",
       "         [  2.10000000e-01,   1.05000000e+00,   8.27000000e+00],\n",
       "         [  8.15000000e-01,   2.33000000e+00,   2.89000000e+00],\n",
       "         [  2.56200000e-01,   1.40270000e+00,   1.97750000e+00],\n",
       "         [  6.61000000e-02,   1.55000000e+00,   2.36380000e+00],\n",
       "         [  2.35070000e+00,   2.25822000e+01,   6.01855000e+01],\n",
       "         [  5.36000000e-02,   4.67100000e-01,   9.08000000e-02],\n",
       "         [  2.14000000e-01,   1.54000000e+00,   7.57000000e+00],\n",
       "         [  5.91000000e-02,   8.24000000e-01,              nan],\n",
       "         [  4.55000000e-02,   1.42000000e-02,              nan]],\n",
       " \n",
       "        [[  2.27000000e-01,   3.78000000e-01,              nan],\n",
       "         [  6.45000000e-02,   3.66000000e-01,              nan],\n",
       "         [  2.61000000e-01,   1.15000000e+00,   3.43000000e-01],\n",
       "         [  1.46000000e+00,   2.62000000e-02,   4.32000000e-01],\n",
       "         [  3.45000000e-01,   3.69000000e-01,   1.44000000e+01],\n",
       "         [  2.10000000e-01,   1.05000000e+00,   8.27000000e+00],\n",
       "         [  8.15000000e-01,   2.33000000e+00,   2.89000000e+00],\n",
       "         [  2.56200000e-01,   1.40270000e+00,   1.97750000e+00],\n",
       "         [  6.61000000e-02,   1.55000000e+00,   2.36380000e+00],\n",
       "         [  2.35070000e+00,   2.25822000e+01,   6.01855000e+01],\n",
       "         [  5.36000000e-02,   4.67100000e-01,   9.08000000e-02],\n",
       "         [  2.14000000e-01,   1.54000000e+00,   7.57000000e+00],\n",
       "         [  5.91000000e-02,   8.24000000e-01,              nan],\n",
       "         [  4.55000000e-02,   1.42000000e-02,              nan]]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbr_sets = 2\n",
    "shape = (nbr_sets, *np.shape(times))\n",
    "sim = np.empty(shape)\n",
    "for i in range(nbr_sets):\n",
    "    sim[i] = times\n",
    "sim[0, :, 0], sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulated chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  6.14678440e-01,   6.70126764e-01,              nan],\n",
       "        [  3.40053986e-02,   8.22395282e-01,              nan],\n",
       "        [  8.03856992e-01,   5.77115912e-01,   1.35687003e-01],\n",
       "        ..., \n",
       "        [  3.51631776e-01,   2.44450327e+00,   1.35385812e+00],\n",
       "        [  7.16541237e-01,   1.74881141e+00,              nan],\n",
       "        [  1.68238359e-04,   9.86797818e-01,              nan]],\n",
       "\n",
       "       [[  4.08016313e-01,   2.20555277e-01,              nan],\n",
       "        [  6.50434323e-02,   2.28892836e-01,              nan],\n",
       "        [  9.41885510e-02,   3.49063474e+00,   9.09514174e-01],\n",
       "        ..., \n",
       "        [  4.28603400e-01,   2.49660559e+00,   2.74070404e+00],\n",
       "        [  1.72839191e+00,   1.07022681e-01,              nan],\n",
       "        [  1.16102622e+00,   3.42278347e+00,              nan]],\n",
       "\n",
       "       [[  1.34881213e+00,   6.09297376e-01,              nan],\n",
       "        [  1.32447293e+00,   9.50221051e-01,              nan],\n",
       "        [  3.85982074e+00,   2.25543466e+00,   2.26560647e+00],\n",
       "        ..., \n",
       "        [  1.35275908e+00,   2.36341250e-01,   1.78049807e+00],\n",
       "        [  1.08327628e-01,   2.64399511e-02,              nan],\n",
       "        [  7.17537754e-01,   2.36224084e-01,              nan]],\n",
       "\n",
       "       ..., \n",
       "       [[  4.90642782e-01,   3.54554376e+00,              nan],\n",
       "        [  3.79623002e+00,   5.66689992e-01,              nan],\n",
       "        [  2.44700563e+00,   3.77415429e-01,   9.23222558e-01],\n",
       "        ..., \n",
       "        [  6.90215993e-01,   2.68168777e-01,   3.10138996e+00],\n",
       "        [  9.63770816e-01,   3.12342956e-01,              nan],\n",
       "        [  2.48211682e+00,   1.17952708e+00,              nan]],\n",
       "\n",
       "       [[  1.04259558e+00,   2.99095253e-02,              nan],\n",
       "        [  1.16192985e+00,   5.24760374e-01,              nan],\n",
       "        [  4.43196909e+00,   1.39686345e+00,   6.57892232e-02],\n",
       "        ..., \n",
       "        [  9.93655360e-01,   2.61143609e+00,   3.75490177e-01],\n",
       "        [  4.79863599e-01,   2.94159605e-01,              nan],\n",
       "        [  1.65784667e-01,   8.25968097e-02,              nan]],\n",
       "\n",
       "       [[  2.84487085e-01,   7.35736113e-01,              nan],\n",
       "        [  2.45311836e+00,   1.55166154e-01,              nan],\n",
       "        [  2.46316026e+00,   1.62575080e+00,   5.78444766e-01],\n",
       "        ..., \n",
       "        [  8.39416853e-01,   8.17909828e-01,   2.56064646e-02],\n",
       "        [  1.57257060e-01,   1.30037493e+00,              nan],\n",
       "        [  2.61344762e+00,   1.22452633e+00,              nan]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbr_sets = 30000\n",
    "shape = (nbr_sets, *np.shape(times))\n",
    "sim = np.random.exponential(scale=1, size=shape)\n",
    "for i in range(nbr_sets):\n",
    "    sim[i][np.isnan(times)] = np.nan\n",
    "sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.0564578   1.05680423  1.08838862 ...,  0.94250492  0.92210166\n",
      "  0.80971526]\n"
     ]
    }
   ],
   "source": [
    "theta = np.log(sim)\n",
    "theta_var = np.zeros(np.shape(theta))\n",
    "gen_Schmidt = np.zeros(np.shape(theta)[:-1])\n",
    "for i in range(nbr_sets):\n",
    "    theta_var[i] = np.square(theta[i] - np.nanmean(theta[i], axis=0))\n",
    "    gen_Schmidt[i] = g_nan_mean(theta_var[i])\n",
    "\n",
    "#theta_var\n",
    "gen_Schmidt = np.sqrt(np.mean(gen_Schmidt, axis=1))\n",
    "print(gen_Schmidt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected generalised Schmidt value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8611277569069522"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E_Schmidt = np.mean(gen_Schmidt)\n",
    "E_Schmidt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.62693873367090591, 1.1338703581954228)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(gen_Schmidt, q=5), np.percentile(gen_Schmidt, q=95)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

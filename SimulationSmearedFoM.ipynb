{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation of smeared FoM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. For the first decay step, a random τ1was picked according to the τlikelihood function h(τ ) (see Fig. 4). Fourteen random lifetimes from the exponential distribution g(t)defined by this τ1were generated. \n",
    "2. For the second decay step, a random τ2was picked according to the τlikelihood function  h(τ ). Fourteen random lifetimes from the exponential distribution g(t)defined by this τ 2 were generated. \n",
    "3. For the third decay step, a random τ3was picked according to the τlikelihood function  h(τ ). Ten random lifetimes from the exponential distribution g(t)defined by this τ3were  generated. \n",
    "4. The generated lifetimes were collected in fourteen chains – ten with three lifetimes, and four  with two lifetimes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, sys, yaml, re\n",
    "from IPython.display import display, Markdown, Latex #Can write latex too!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DecayChain(yaml.YAMLObject):\n",
    "    \n",
    "    yaml_tag = u'!DecayChain'\n",
    "    \n",
    "    def __init__(self, idd=\"\", be=\"\", pi=\"\", ie=\"\", it=\"\", ea=[], eas=[], ta=[]):\n",
    "        self.ID = idd\n",
    "        self.BeamEnergy = be\n",
    "        self.Pixel = pi\n",
    "        self.ImplantEnergy = ie\n",
    "        self.ImplantTime = it\n",
    "        self.EAlpha, self.EAlphaSigma, self.TAlpha = ea, eas, ta\n",
    "\n",
    "class SetDecayChains:\n",
    "    \n",
    "    def __init__(self, path='', ids=[]):\n",
    "        s_files = \" \".join(os.listdir(path))\n",
    "        files = []\n",
    "        for s in ids:\n",
    "            files += (sorted(re.findall(string=s_files, pattern=\"Chain\"+s+\"\\d+.yml\")))\n",
    "        print(\"Reading the following files:\", files)\n",
    "        self.Chains = []\n",
    "        for f in files:\n",
    "            f_in = open(path+f, 'r')\n",
    "            self.Chains.append(yaml.load(f_in))\n",
    "            f_in.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the following files: ['Chain1401.yml', 'Chain1402.yml', 'Chain1403.yml', 'Chain1404.yml', 'Chain1405.yml', 'Chain1406.yml', 'Chain1407.yml', 'Chain1101.yml', 'Chain1102.yml', 'Chain1103.yml', 'Chain1104.yml', 'Chain1701.yml', 'Chain1702.yml', 'Chain1703.yml']\n",
      "Max steps= 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  2.27000000e-01,   3.78000000e-01,              nan],\n",
       "       [  6.45000000e-02,   3.66000000e-01,              nan],\n",
       "       [  2.61000000e-01,   1.15000000e+00,   3.43000000e-01],\n",
       "       [  1.46000000e+00,   2.62000000e-02,   4.32000000e-01],\n",
       "       [  3.45000000e-01,   3.69000000e-01,   1.44000000e+01],\n",
       "       [  2.10000000e-01,   1.05000000e+00,   8.27000000e+00],\n",
       "       [  8.15000000e-01,   2.33000000e+00,   2.89000000e+00],\n",
       "       [  2.56200000e-01,   1.40270000e+00,   1.97750000e+00],\n",
       "       [  6.61000000e-02,   1.55000000e+00,   2.36380000e+00],\n",
       "       [  2.35070000e+00,   2.25822000e+01,   6.01855000e+01],\n",
       "       [  5.36000000e-02,   4.67100000e-01,   9.08000000e-02],\n",
       "       [  2.14000000e-01,   1.54000000e+00,   7.57000000e+00],\n",
       "       [  5.91000000e-02,   8.24000000e-01,              nan],\n",
       "       [  4.55000000e-02,   1.42000000e-02,              nan]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_path = \"E115_Chains/\"\n",
    "s_id = [\"14\", \"11\", \"17\"]\n",
    "\n",
    "setDC = SetDecayChains(s_path, s_id)\n",
    "max_steps = 0\n",
    "for chain in setDC.Chains:\n",
    "    if len(chain.TAlpha) > max_steps:\n",
    "        max_steps = len(chain.TAlpha)\n",
    "print(\"Max steps=\", max_steps)\n",
    "times = np.zeros((len(setDC.Chains), max_steps))\n",
    "for row, chain in enumerate(setDC.Chains):\n",
    "    steps = len(chain.TAlpha)\n",
    "    for i in range(max_steps):\n",
    "        if i < steps:\n",
    "            times[row][i] = chain.TAlpha[i]\n",
    "        else:\n",
    "            times[row][i] = np.nan       \n",
    "times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14, 14, 10])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_j = np.count_nonzero(~np.isnan(times), axis=0)\n",
    "N_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.45912143,  2.4321    ,  9.85226   ])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_mean_j = np.nanmean(times, axis=0)\n",
    "t_mean_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class tau_likelihood_func:\n",
    "    def __init__(self, t_mean, N_j):\n",
    "        self.t_mean = t_mean\n",
    "        self.N_j = N_j\n",
    "        self.factor1 = np.divide(np.multiply(np.power(self.N_j, self.N_j-1), np.power(self.t_mean, self.N_j-1)), factorial() \n",
    "\n",
    "    def __call__(self, tau):\n",
    "        ret = np.empty((len(tau), len(self.N_j)))\n",
    "        np.exp(np.multiply(self.N_j))\n",
    "        return 0\n",
    "\n",
    "tau_likelihood = tau_likelihood_func(t_mean_j, N_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tau = np.linspace(0, max(t_mean_j)*5, 1000)\n",
    "print(len(tau))\n",
    "tau_likelihood(tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  6.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.special import factorial\n",
    "factorial(np.array([2, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each step j, the likelihood function for the true lifetime τj, given by Njand  ̄tj, is  determined. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each step j, a τjis selected with a probability governed by the likelihood function for  τj, and then a set of Njlifetimes are generated from the exponential distribution defined by  this τj. This procedure is repeated until a smooth histogram emerges."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
